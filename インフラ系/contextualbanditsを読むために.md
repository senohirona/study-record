# what
 - [contextualbandits](https://github.com/david-cortes/contextualbandits) を読むために、必要な知識やそれについて調べたことを記載する



# ライブラリを理解するために必要となる知識
- 確率の知識
    - contextualbanditsについてそもそも理解するには必要になる
- 一覧
    - 確率分布
    - 二項分布
    - ベータ分布
    -  バンディットの基礎
        - UCB1
        - イプシロングリーディー
        - トンプソンサンプリング　<-特にこれ
    - 機械学習を使ったバンディット(文脈付きバンディット 　<-特にこれ
- python

# 各確率の知識について

- 個人的に調べたものばかりなので、なんとも言えない表現をしているものもあり

## 確率分布(確率密度関数)

- `確率変数(ある変数の値をとる確率が存在する変数)`がとる値とその値をとる確率の対応の様子
- 「データが出てくる確率の一覧」とも言う
    - 例) コイントスの場合、「表、裏」の2つなので「表:50% 裏:50%」のとなるはず。この確率の集合の事
- ref: [確率分布と確率変数の基礎](https://logics-of-blue.com/%E7%A2%BA%E7%8E%87%E5%88%86%E5%B8%83%E3%81%A8%E7%A2%BA%E7%8E%87%E5%A4%89%E6%95%B0%E3%81%AE%E5%9F%BA%E7%A4%8E/)
### 注意点
- 1/2で表が出るコインと50 / 100 で表が出るコインは、確率密度分布の世界では全く違う
- 試行回数が多ければ多いほど、真の確率を推定しやすくなる

## 二項分布
- 試行結果が「○ or ☓」や「成功 or 失敗」と言った2種類しかない試行の事を統計学では「ベルヌーイ試行」と呼ぶ
- 二項分布は、「互いに独立したベルヌーイ試行をn回行ったときにある事象が何回起こるかの確率分布」の事を言う
    - 例) 「30％の確率で表が出る特殊なコインを4回投げた時、表がk回出る確率の分布」
    - 例2) 「サイコロを200回投げたときに、1の目がk回出る確率の分布」
- ref: [コイン投げから分かる二項分布。正規分布やポアソン分布との関係性と近似について
ツイート
](https://atarimae.biz/archives/7922)
    - [二項分布 --統計WEB](https://bellcurve.jp/statistics/course/6979.html)

## ベータ分布

- 試行回数と成功回数を渡すと分布が返ってくる
    - [コインで理解するベータ分布](http://r-tips.hatenablog.com/entry/beta-distribution)

## バンディットの基礎
- 目指すのは累積報酬の最大化
    - 有限回の試行の中で報酬を最大化するには、優れたアーム(選択肢)を多く引き、劣ったアームは引く回数を抑えることが必要となる
    - どれが良いアーム化を探りつつ(探索)、良さそうなアームを積極的に引いていく(活用)のがバンディットの本質
-  例)コインが２つあるとき、最も表の出る確率が高いコインを推定したい
    - 確率密度分布が２つある。
    - 各コインの表の出る確率は異なる
- ref: [バンディットアルゴリズム入門と実践](https://www.slideshare.net/greenmidori83/ss-28443892)


### UCB1
- バンディットの方策の1種
    - アームについてどれだけ知っているか考慮に入れてアームを選択する
        - **知らないアーム(不確かな選択肢)について積極的に探索を行う**
    - 評価表から評価値を求め、評価値が最も高いアームを引く
- デメリット
    - 試行回数が少ないもの＆（運悪く）確率が低く推定されている場合、探索されにくくなってしまう
    - （試行回数が少なくても）確率が高く推定されていれば、より優先して探索されてしまう
- ref: [バンディットアルゴリズム入門と実践](https://www.slideshare.net/greenmidori83/ss-28443892)

### ε(イプシロン)グリーディー
- バンディットの方策の1種で、最も単純な方法(らしい)
    - 下記のような流れで累積報酬の最大化を目指す
        - 探索時: すべてのアームをランダムに選択
        - 活用時: それまでの思考の結果から、報酬の標本平均の最も高かったアームを選択
- メリット
    - 確率分布を考えなくても使える
- デメリット
    - 明らかに探索し終えているにもかかわらず、探索をしてしまう(重複して探索してしまう)
- ref: [バンディットアルゴリズム　基本編](https://blog.albert2005.co.jp/2017/01/23/バンディットアルゴリズム%E3%80%80基本編/)

### トンプソンサンプリング(トンプソン抽出)
- バンディットの方策の1種
    - 確率密度分布から、得られる乱数をもとに確率分の真の確率の大小を比較する
    - 数学的な関数に従わなくても推定された確率に従って乱数を取得ができる
- ref: [バンディットアルゴリズム　基本編](https://blog.albert2005.co.jp/2017/01/23/バンディットアルゴリズム%E3%80%80基本編/)

### 機械学習を使ったバンディット(文脈付きバンディット)
- 事前にアームの報酬に対して仮定した確率分布のパラメータを文脈に応じて変化させることで, より効率的に報酬を最大化すること
    - 文脈（ユーザーの特徴など, context）に応じて各アームの報酬構造が変化すると考えている
- netflexでも使われているらしい
    - [Netflixも使っている！Contextual Banditアルゴリズムを徹底解説！（Part 1）](https://qiita.com/usaito/items/e727dcac7325b50d4d4c)
- 例) θ = f(x)と考えるとき
    - x = Aさん（ユーザーベクトル）
    - 複数のモデルから、θを推定し、複数の予測値を得る
    - そのデータを元に確率密度分布を得る
    - これを各アーム数分行い、アーム分の確率密度分布からトンプソンサンプリングを行い、最も確率の高いアームを得る
